2025-08-21 17:30:40,195 [ERROR] registry.ollama.ai/library/llama2:latest does not support tools (status code: 400)
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\endpoints.py", line 23, in research
    return research_service.run(request.query, formatted_history)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\services\ollama_service.py", line 29, in run
    raw_response = self.agent_executor.invoke({"query": query, "chat_history": chat_history})
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 170, in invoke
    raise e
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 160, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1624, in _call
    next_step_output = self._take_next_step(
        name_to_tool_map,
    ...<3 lines>...
        run_manager=run_manager,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1332, in _take_next_step
    for a in self._iter_next_step(
             ~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map,
        ^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        run_manager,
        ^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1358, in _iter_next_step
    output = self._action_agent.plan(
        intermediate_steps,
        callbacks=run_manager.get_child() if run_manager else None,
        **inputs,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 581, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
                 ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
    ...<4 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
                  ^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
    ...<3 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 902, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 841, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 740, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\ollama\_client.py", line 170, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: registry.ollama.ai/library/llama2:latest does not support tools (status code: 400)
2025-08-21 17:37:11,563 [ERROR] registry.ollama.ai/library/llama3:latest does not support tools (status code: 400)
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\endpoints.py", line 23, in research
    return research_service.run(request.query, formatted_history)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\services\ollama_service.py", line 29, in run
    raw_response = self.agent_executor.invoke({"query": query, "chat_history": chat_history})
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 170, in invoke
    raise e
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 160, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1624, in _call
    next_step_output = self._take_next_step(
        name_to_tool_map,
    ...<3 lines>...
        run_manager=run_manager,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1332, in _take_next_step
    for a in self._iter_next_step(
             ~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map,
        ^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        run_manager,
        ^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1358, in _iter_next_step
    output = self._action_agent.plan(
        intermediate_steps,
        callbacks=run_manager.get_child() if run_manager else None,
        **inputs,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 581, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
                 ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
    ...<4 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
                  ^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
    ...<3 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 902, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 841, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 740, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\ollama\_client.py", line 170, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: registry.ollama.ai/library/llama3:latest does not support tools (status code: 400)
2025-08-21 17:50:21,018 [ERROR] model requires more system memory (11.5 GiB) than is available (9.2 GiB) (status code: 500)
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\endpoints.py", line 23, in research
    return research_service.run(request.query, formatted_history)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\services\ollama_service.py", line 29, in run
    raw_response = self.agent_executor.invoke({"query": query, "chat_history": chat_history})
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 170, in invoke
    raise e
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 160, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1624, in _call
    next_step_output = self._take_next_step(
        name_to_tool_map,
    ...<3 lines>...
        run_manager=run_manager,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1332, in _take_next_step
    for a in self._iter_next_step(
             ~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map,
        ^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        run_manager,
        ^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1358, in _iter_next_step
    output = self._action_agent.plan(
        intermediate_steps,
        callbacks=run_manager.get_child() if run_manager else None,
        **inputs,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 581, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
                 ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
    ...<4 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
                  ^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
    ...<3 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 902, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 841, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 740, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\ollama\_client.py", line 170, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model requires more system memory (11.5 GiB) than is available (9.2 GiB) (status code: 500)
2025-08-21 17:57:36,613 [ERROR] registry.ollama.ai/library/deepseek-r1:latest does not support tools (status code: 400)
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\endpoints.py", line 23, in research
    return research_service.run(request.query, formatted_history)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\services\ollama_service.py", line 29, in run
    raw_response = self.agent_executor.invoke({"query": query, "chat_history": chat_history})
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 170, in invoke
    raise e
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 160, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1624, in _call
    next_step_output = self._take_next_step(
        name_to_tool_map,
    ...<3 lines>...
        run_manager=run_manager,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1332, in _take_next_step
    for a in self._iter_next_step(
             ~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map,
        ^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        run_manager,
        ^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1358, in _iter_next_step
    output = self._action_agent.plan(
        intermediate_steps,
        callbacks=run_manager.get_child() if run_manager else None,
        **inputs,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 581, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
                 ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
    ...<4 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
                  ^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
    ...<3 lines>...
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 902, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 841, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_ollama\chat_models.py", line 740, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\ollama\_client.py", line 170, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: registry.ollama.ai/library/deepseek-r1:latest does not support tools (status code: 400)
2025-08-21 20:08:23,155 [ERROR] Too many arguments to single-input tool GetCurrentDateTime.
                Consider using StructuredTool instead. Args: []
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\endpoints.py", line 23, in research
    result = research_service.run(request.query, formatted_history)
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\services\ollama_service.py", line 29, in run
    raw_response = self.agent_executor.invoke({"query": query, "chat_history": chat_history})
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 170, in invoke
    raise e
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\chains\base.py", line 160, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1624, in _call
    next_step_output = self._take_next_step(
        name_to_tool_map,
    ...<3 lines>...
        run_manager=run_manager,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1332, in _take_next_step
    for a in self._iter_next_step(
             ~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map,
        ^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        run_manager,
        ^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1415, in _iter_next_step
    yield self._perform_agent_action(
          ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        name_to_tool_map, color_mapping, agent_action, run_manager
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain\agents\agent.py", line 1437, in _perform_agent_action
    observation = tool.run(
        agent_action.tool_input,
    ...<3 lines>...
        **tool_run_kwargs,
    )
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\tools\base.py", line 883, in run
    raise error_to_raise
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\tools\base.py", line 845, in run
    tool_args, tool_kwargs = self._to_args_and_kwargs(
                             ~~~~~~~~~~~~~~~~~~~~~~~~^
        tool_input, tool_call_id
        ^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\langchain_core\tools\simple.py", line 89, in _to_args_and_kwargs
    raise ToolException(msg)
langchain_core.tools.base.ToolException: Too many arguments to single-input tool GetCurrentDateTime.
                Consider using StructuredTool instead. Args: []
2025-10-26 16:25:37,057 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-10-26 16:25:40,382 [ERROR] Erro ao inserir conta bancária: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-10-26 16:27:11,482 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-10-26 16:27:24,618 [ERROR] Erro ao inserir conta bancária: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-12-17 22:35:53,577 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-17 22:35:53,577 [INFO] [33mPress CTRL+C to quit[0m
2025-12-17 22:37:05,547 [INFO] 127.0.0.1 - - [17/Dec/2025 22:37:05] "[33mPOST /api/v1/bot HTTP/1.1[0m" 404 -
2025-12-17 22:40:07,634 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-17 22:40:07,634 [INFO] [33mPress CTRL+C to quit[0m
2025-12-17 22:42:28,978 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-17 22:42:28,978 [INFO] [33mPress CTRL+C to quit[0m
2025-12-17 22:45:19,130 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-17 22:45:19,130 [INFO] [33mPress CTRL+C to quit[0m
2025-12-17 22:47:10,762 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-17 22:47:10,762 [INFO] [33mPress CTRL+C to quit[0m
2025-12-17 22:51:25,235 [INFO] 127.0.0.1 - - [17/Dec/2025 22:51:25] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-17 22:52:10,854 [INFO] 127.0.0.1 - - [17/Dec/2025 22:52:10] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-17 22:53:44,403 [INFO] 127.0.0.1 - - [17/Dec/2025 22:53:44] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:19:35,847 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:19:35,847 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:24:26,575 [INFO] 127.0.0.1 - - [23/Dec/2025 16:24:26] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:25:12,076 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-12-23 16:25:13,803 [INFO] 127.0.0.1 - - [23/Dec/2025 16:25:13] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:29:41,329 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:29:41,330 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:30:13,890 [INFO] 127.0.0.1 - - [23/Dec/2025 16:30:13] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:30:19,844 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-12-23 16:30:22,578 [ERROR] Missing Twilio REST credentials or routing numbers; sent no REST message.
NoneType: None
2025-12-23 16:35:15,055 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:35:15,055 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:37:32,121 [INFO] 127.0.0.1 - - [23/Dec/2025 16:37:32] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:40:12,082 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:40:12,082 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:42:05,782 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:42:05,783 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:42:09,508 [ERROR] 'str' object has no attribute 'get'
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\financial_agent_endpoint.py", line 23, in bot
    incoming_msg = payload.get("query") or request.values.get("Body", "")
                   ^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
2025-12-23 16:42:09,513 [INFO] 127.0.0.1 - - [23/Dec/2025 16:42:09] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:42:33,598 [ERROR] 'str' object has no attribute 'get'
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\financial_agent_endpoint.py", line 23, in bot
    incoming_msg = payload.get("query") or request.values.get("Body", "")
                   ^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
2025-12-23 16:42:36,404 [INFO] 127.0.0.1 - - [23/Dec/2025 16:42:36] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:43:17,273 [ERROR] 'str' object has no attribute 'get'
Traceback (most recent call last):
  File "C:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\app\api\financial_agent_endpoint.py", line 23, in bot
    incoming_msg = payload.get("query") or request.values.get("Body", "")
                   ^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
2025-12-23 16:43:17,278 [INFO] 127.0.0.1 - - [23/Dec/2025 16:43:17] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:44:11,039 [INFO] 127.0.0.1 - - [23/Dec/2025 16:44:11] "[35m[1mPOST /api/v1/bot HTTP/1.1[0m" 500 -
2025-12-23 16:44:11,059 [ERROR] Error on request:
Traceback (most recent call last):
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\werkzeug\serving.py", line 370, in run_wsgi
    execute(self.server.app)
    ~~~~~~~^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\werkzeug\serving.py", line 331, in execute
    application_iter = app(environ, start_response)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 1536, in __call__
    return self.wsgi_app(environ, start_response)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 1514, in wsgi_app
    response = self.handle_exception(e)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
           ~~~~~~~~~~~~~~~~~~~~~^^^^
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "c:\Users\vitor\OneDrive\Documentos\Projects\ControleFinanceiro\.venv\Lib\site-packages\flask\app.py", line 1249, in make_response
    raise TypeError(
    ^
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a Body.
2025-12-23 16:45:57,436 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:45:57,436 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:46:06,945 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-12-23 16:46:08,770 [INFO] 127.0.0.1 - - [23/Dec/2025 16:46:08] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:47:30,247 [ERROR] Erro na conexão com o banco: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-12-23 16:47:32,862 [INFO] 127.0.0.1 - - [23/Dec/2025 16:47:32] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:54:08,315 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:54:08,315 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:54:16,916 [ERROR] Erro na conexão com o banco: relation "CARTOES_DE_CREDITO" does not exist
LINE 1: SELECT * FROM "CARTOES_DE_CREDITO"
                      ^

2025-12-23 16:54:18,412 [INFO] 127.0.0.1 - - [23/Dec/2025 16:54:18] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-23 16:55:43,558 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-23 16:55:43,559 [INFO] [33mPress CTRL+C to quit[0m
2025-12-23 16:55:51,016 [INFO] 127.0.0.1 - - [23/Dec/2025 16:55:51] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 16:56:38,704 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-25 16:56:38,706 [INFO] [33mPress CTRL+C to quit[0m
2025-12-25 16:57:21,576 [ERROR] Erro na conexão com o banco: module 'psycopg2' has no attribute 'extras'
2025-12-25 16:57:23,210 [INFO] 127.0.0.1 - - [25/Dec/2025 16:57:23] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 16:59:55,465 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-25 16:59:55,466 [INFO] [33mPress CTRL+C to quit[0m
2025-12-25 17:02:51,746 [INFO] 127.0.0.1 - - [25/Dec/2025 17:02:51] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:08:26,349 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-25 17:08:26,350 [INFO] [33mPress CTRL+C to quit[0m
2025-12-25 17:10:03,761 [INFO] 127.0.0.1 - - [25/Dec/2025 17:10:03] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:10:33,101 [INFO] 127.0.0.1 - - [25/Dec/2025 17:10:33] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:15:19,916 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-25 17:15:19,916 [INFO] [33mPress CTRL+C to quit[0m
2025-12-25 17:15:32,858 [INFO] 127.0.0.1 - - [25/Dec/2025 17:15:32] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:17:16,418 [INFO] 127.0.0.1 - - [25/Dec/2025 17:17:16] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:18:10,959 [INFO] 127.0.0.1 - - [25/Dec/2025 17:18:10] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:19:53,229 [INFO] 127.0.0.1 - - [25/Dec/2025 17:19:53] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:19:54,651 [INFO] 127.0.0.1 - - [25/Dec/2025 17:19:54] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:20:21,231 [INFO] 127.0.0.1 - - [25/Dec/2025 17:20:21] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:20:38,135 [INFO] 127.0.0.1 - - [25/Dec/2025 17:20:38] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:21:17,167 [INFO] 127.0.0.1 - - [25/Dec/2025 17:21:17] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:22:13,806 [INFO] 127.0.0.1 - - [25/Dec/2025 17:22:13] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:23:06,157 [INFO] 127.0.0.1 - - [25/Dec/2025 17:23:06] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:23:27,247 [INFO] 127.0.0.1 - - [25/Dec/2025 17:23:27] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-25 17:25:17,140 [ERROR] Erro na conexão com o banco: invalid input syntax for type integer: "Mercado"
LINE 1: ...2025-12-25'::date, 'mercadinho do concominio', 1, 'Mercado',...
                                                             ^

2025-12-25 17:25:18,842 [INFO] 127.0.0.1 - - [25/Dec/2025 17:25:18] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:01:57,700 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:01:57,701 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:35:49,369 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:35:49,369 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:37:16,130 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:37:16,130 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:37:45,444 [ERROR] Erro na conexão com o banco: value too long for type character varying(20)

2025-12-30 20:37:45,445 [ERROR] Erro ao salvar mensagem: value too long for type character varying(20)

2025-12-30 20:38:08,050 [ERROR] Erro na conexão com o banco: value too long for type character varying(20)

2025-12-30 20:38:08,050 [ERROR] Erro ao salvar mensagem: value too long for type character varying(20)

2025-12-30 20:38:10,711 [INFO] 127.0.0.1 - - [30/Dec/2025 20:38:10] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:41:32,199 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:41:32,199 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:41:45,273 [INFO] 127.0.0.1 - - [30/Dec/2025 20:41:45] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:43:17,027 [INFO] 127.0.0.1 - - [30/Dec/2025 20:43:17] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:46:02,843 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:46:02,843 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:46:11,645 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...teudo_mensagem': 'olá'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...teudo_mensagem': 'olá'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:46:11,645 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...r suas finanças hoje?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...r suas finanças hoje?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:46:19,001 [INFO] 127.0.0.1 - - [30/Dec/2025 20:46:19] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:46:47,673 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...teudo_mensagem': 'olá'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...teudo_mensagem': 'olá'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:46:47,674 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...r suas finanças hoje?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...r suas finanças hoje?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:46:47,674 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...á gastei até agora ?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'user...á gastei até agora ?'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:46:47,674 [ERROR] Erro ao descriptografar mensagem: 2 validation errors for Message
role
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...gistrado nenhum gasto.'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
content
  Field required [type=missing, input_value={'tipo_mensageiro': 'bot'...gistrado nenhum gasto.'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
2025-12-30 20:48:09,909 [INFO] 127.0.0.1 - - [30/Dec/2025 20:48:09] "POST /api/v1/bot HTTP/1.1" 200 -
2025-12-30 20:49:35,182 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-30 20:49:35,183 [INFO] [33mPress CTRL+C to quit[0m
2025-12-30 20:50:54,865 [INFO] 127.0.0.1 - - [30/Dec/2025 20:50:54] "POST /api/v1/bot HTTP/1.1" 200 -
